<script src="http://www.google.com/jsapi" type="text/javascript"></script> 
<script type="text/javascript">google.load("jquery", "1.3.2");</script>

<style type="text/css">
	body {
		font-family: "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif; 
		font-weight:300;
		font-size:18px;
		margin-left: auto;
		margin-right: auto;
		width: 1100px;
	}
	
	h1 {
		font-size:32px;
		font-weight:300;
	}
	
	.disclaimerbox {
		background-color: #eee;		
		border: 1px solid #eeeeee;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
		padding: 20px;
	}

	video.header-vid {
		height: 140px;
		border: 1px solid black;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}
	
	img.header-img {
		height: 140px;
		border: 1px solid black;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}
	
	img.rounded {
		border: 1px solid #eeeeee;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}
	
	a:link,a:visited
	{
		color: #1367a7;
		text-decoration: none;
	}
	a:hover {
		color: #208799;
	}
	
	td.dl-link {
		height: 160px;
		text-align: center;
		font-size: 22px;
	}
	
	.layered-paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
		5px 5px 0 0px #fff, /* The second layer */
		5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
		10px 10px 0 0px #fff, /* The third layer */
		10px 10px 1px 1px rgba(0,0,0,0.35), /* The third layer shadow */
		15px 15px 0 0px #fff, /* The fourth layer */
		15px 15px 1px 1px rgba(0,0,0,0.35), /* The fourth layer shadow */
		20px 20px 0 0px #fff, /* The fifth layer */
		20px 20px 1px 1px rgba(0,0,0,0.35), /* The fifth layer shadow */
		25px 25px 0 0px #fff, /* The fifth layer */
		25px 25px 1px 1px rgba(0,0,0,0.35); /* The fifth layer shadow */
		margin-left: 10px;
		margin-right: 45px;
	}

	.paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		0px 0px 1px 1px rgba(0,0,0,0.35); /* The top layer shadow */

		margin-left: 10px;
		margin-right: 45px;
	}


	.layered-paper { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
		5px 5px 0 0px #fff, /* The second layer */
		5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
		10px 10px 0 0px #fff, /* The third layer */
		10px 10px 1px 1px rgba(0,0,0,0.35); /* The third layer shadow */
		margin-top: 5px;
		margin-left: 10px;
		margin-right: 30px;
		margin-bottom: 5px;
	}
	
	.vert-cent {
		position: relative;
		top: 50%;
		transform: translateY(-50%);
	}
	
	hr
	{
		border: 0;
		height: 1px;
		background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.75), rgba(0, 0, 0, 0));
	}
</style>

<html>
<head>
	<title>Photorealistic Image Reconstruction from Hybrid Intensity and Event-based Sensor</title>
	<meta property="og:image" content="./resources/teaser.png"/> <!-- Facebook automatically scrapes this. Go to https://developers.facebook.com/tools/debug/ if you update and want to force Facebook to rescrape. -->
	<meta property="og:title" content="Photorealistic Image Reconstruction from Hybrid Intensity and Event-based Sensor" />
	<meta property="og:description" content="An image reconstruction pipeline for event sensors" />

	<!-- Get from Google Analytics -->
	<!-- Global site tag (gtag.js) - Google Analytics -->
	<script async src=""></script> 
	<script>
		window.dataLayer = window.dataLayer || [];
		function gtag(){dataLayer.push(arguments);}
		gtag('js', new Date());

		gtag('config', 'UA-75863369-6');
	</script>
</head>

<body>
	<br>
	<center>
		<span style="font-size:36px">High Frame Rate Optical Flow Estimation from Event Sensors via Intensity Estimation</span>
		<table align=center width=600px>
			<table align=center width=600px>
				<tr>
					<td align=center width=100px>
						<center>
							<span style="font-size:24px"><a href="https://asprasan.github.io">Prasan Shedligeri</a></span>
						</center>
					</td>
					<td align=center width=100px>
						<center>
							<span style="font-size:24px"><a href="http://www.ee.iitm.ac.in/kmitra/">Kaushik Mitra</a></span>
						</center>
					</td>
				</tr>
			</table>
			<table align=center width=250px>
				<tr>
					<td align=center width=120px>
						<center>
							<span style="font-size:24px"><a href='./resources/paper.pdf'>[Paper]</a></span>
						</center>
					</td>
					<!-- <td align=center width=120px>
						<center>
							<span style="font-size:24px"><a href='https://github.com/asprasan/codedblurred'>[GitHub]</a></span><br>
						</center>
					</td> -->
				</tr>
			</table>
		</table>
	</center>

	<center>
		<!-- <table align=center width=850px> -->
			<style type="text/css">
.tg  {border:none;border-collapse:collapse;border-spacing:0;}
.tg td{border-style:solid;border-width:0px;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;
  padding:5px 5px;word-break:normal;}
.tg th{border-style:solid;border-width:0px;font-family:Arial, sans-serif;font-size:14px;font-weight:normal;
  overflow:hidden;padding:10px 5px;word-break:normal;}
.tg .tg-8jgo{border-color:#ffffff;text-align:center;vertical-align:center}
.tg .tg-c3ow{border-color:inherit;text-align:center;vertical-align:center}
</style>
<table class="tg">
<!-- <thead>
  <tr>
    <th class="tg-8jgo"></th>
    <th class="tg-8jgo"></th>
    <th class="tg-8jgo">Coded</th>
    <th class="tg-c3ow" colspan="2">Fully exposed - coded (Ours)</th>
  </tr>
</thead> -->
<tbody>
  <tr>
    <td class="tg-8jgo"><img src="./resources/top.png" width="672" height="688"></td>
  </tr>
</tbody>
</table>
			<!-- <tr>
				<td width=260px>
					<center>
						<img class="round" style="width:500px" src="./resources/fusion_teaser.png"/>
					</center>
				</td>
			</tr> -->
		<!-- </table> -->
		<!-- <table align=center width=850px>
			<tr>
				<td>
					This was a template originally made for <a href="http://richzhang.github.io/colorization/">Colorful Image Colorization</a>. The code can be found in this <a href="https://github.com/richzhang/webpage-template">repository</a>.
				</td>
			</tr>
		</table> -->
	</center>

	<hr>

	<table align=center width=850px>
		<center><h1>Abstract</h1></center>
		<tr>
			<td align=justify>
				Event sensors output a stream of asynchronous brightness changes (called ``events'') at a very high temporal rate. Previous works on recovering the lost intensity information from the event sensor data have heavily relied on the event stream, which makes the reconstructed images non-photorealistic and also susceptible to noise in the event stream.
				A method is proposed to reconstruct photorealistic intensity images from a hybrid sensor consisting of a low frame rate conventional camera and the event sensor. The texture-rich information from a traditional image sensor with the motion-rich information from the event sensor is exploited, producing photorealistic high frame rate videos.
				To accomplish the task, the low frame rate intensity images are warped to temporally dense locations of the event data.
				The results obtained from the proposed algorithm are more photorealistic compared to any of the previous state-of-the-art algorithms. The algorithm's robustness to abrupt camera motion and noise in the event sensor data is also demonstrated.

			</td>
		</tr>
	</table>
	<br>

	<!-- <hr>
	<center><h1>Talk</h1></center>
	<p align="center">
		<iframe src="https://drive.google.com/file/d/1wdkF1QapN1bSohgjKV9MqhBl6qrbNJMT/preview" width="660" height="395" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen align="center"></iframe>
	</p>

	<table align=center width=800px>
		<br>
		<tr>
			<center>
				<span style="font-size:28px"><a href='https://docs.google.com/presentation/d/16XcZHiEbf3CfBPd9aU2YyIW-hXrq8Nelwsfb4SY4_Fw/edit?usp=sharing'>[Slides]</a>
				</span>
			</center>
		</tr>
	</table>
	<hr> -->

	<center><h1>Key takeaways</h1></center>

	<table align=center width=800px>
		<center>
			<tr>
				<td>
					<li>
						We propose to exploit a hybrid setup of intensity and event-based sensor for photorealistic, high frame-rate video reconstruction.
					</li>
					<li>
						To accomplish the task, the low frame rate intensity images are warped to temporally dense locations of the event data.
					</li>
					<li>
						The texture-rich information from a traditional image sensor with the motion-rich information from the event sensor is exploited, producing photorealistic high frame rate videos.
					</li>
				</td>
			</tr>
		</center>
	</table>

	<hr>

	<center><h1>Algorithm</h1></center>

	<!-- <table align=center width=640px>
		<center>
			<tr>
				<td>

				</td>
			</tr>
		</center>
	</table> -->
	<table align=center width=600px>
		<tr>
			<td align=center width=600px>
				<center>
					<td><img class="round" style="width:600px" src="./resources/Teaser.png"/></td>
				</center>
			</td>
		</tr>
	</table>
	<table align=center width=850px>
		<center>
			<tr>
				<td align=justify>
					The main blocks of the algorithm are a) an iterative depth and camera pose estimation technique for successive intensity frames, b) mapping event data into pseudo-intensity frames, c) direct visual odometry based sensor ego-motion estimation for intermediate event frame locations and d) a warping module for warping intensity images to intermediate locations.
				</td>
			</tr>
		</center>
	</table>
	<!-- <table align=center width=800px>
		<br>
		<tr><center>
			<span style="font-size:28px">&nbsp;<a href='https://github.com/asprasan/codedblurred'>[GitHub]</a>
			</center>
		</span>
	</table> -->
	<br>
	<hr>
	<table align=center width=450px>
		<center><h1>Paper and Supplementary Material</h1></center>
		<tr>
			<td><a href=""><img class="layered-paper-big" style="height:175px" src="./resources/paper.png"/></a></td>
			<td><span style="font-size:14pt"> P. Shedligeri, Kaushik Mitra<br>
				<b>Photorealistic Image Reconstruction from Hybrid Intensity and Event-based Sensor</b><br>
				Accepted at SPIE Journal of Electronic Imaging, 2020<br>
				(Available as <a href="./resources/paper.pdf">Pre-print</a>)<br>
				<!-- (<a href="./resources/camera-ready.pdf">camera ready</a>)<br> -->
				<span style="font-size:4pt"><a href=""><br></a>
				</span>
			</td>
		</tr>
	</table>
	<br>

	<!-- <table align=center width=300px>
		<tr>
			<td align=center><span style="font-size:14pt">
				<a href="">[Supplementary Material]</a></td>
		</tr>
	</table>
 -->
	<hr>
	<br>

	<center><h1>Related Publications</h1></center>

	<table align=center width=900px>
		<center>
			<tr>
				<td>
					<li>
            <b>Prasan Shedligeri</b> & Kaushik Mitra. (2021), "High Frame Rate Optical Flow Estimation from Event Sensors via Intensity Estimation", <em>Elsevier Journal of Computer Vision and Image Understanding</em>, 208-209, doi:10.1016/j.cviu.2021.103208
            <a href="./pages/webpage-CVIU/resources/paper.pdf" target="_blank" rel="noopener noreferrer">[Preprint]</a>
            <a href="./pages/webpage-CVIU/index.html" target="_blank" rel="noopener noreferrer">[Webpage]</a>
          </li>
				</td>
			</tr>
		</center>
	</table>

	<hr>

	<table align=center width=900px>
		<tr>
			<td width=400px>
				<left>
					<center><h1>Acknowledgements</h1></center>
					The authors would like to thank Matta Gopi Raju for collecting some of the data used in this and related publications.
					<br>
					This template was originally made by <a href="http://web.mit.edu/phillipi/">Phillip Isola</a> and <a href="http://richzhang.github.io/">Richard Zhang</a> for a <a href="http://richzhang.github.io/colorization/">colorful</a> ECCV project; the code can be found <a href="https://github.com/richzhang/webpage-template">here</a>.
				</left>
			</td>
		</tr>
	</table>

<br>
</body>
</html>

