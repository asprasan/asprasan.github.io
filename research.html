<!DOCTYPE html>
<html lang="en">

<head>
   <!-- Metadata for the Webpage -->
   <meta charset="utf-8">
   <meta http-equiv="X-UA-Compatible" content="IE=edge">
   <meta name="viewport" content="width=device-width, initial-scale=1">
   <title>Prasan Shedligeri</title>

   <!-- Favicons -- We recommend this site for generating favicons: https://www.favicon-generator.org/ -->
   <link rel="apple-touch-icon" sizes="57x57" href="favicons/apple-icon-57x57.png">
   <link rel="apple-touch-icon" sizes="60x60" href="favicons/apple-icon-60x60.png">
   <link rel="apple-touch-icon" sizes="72x72" href="favicons/apple-icon-72x72.png">
   <link rel="apple-touch-icon" sizes="76x76" href="favicons/apple-icon-76x76.png">
   <link rel="apple-touch-icon" sizes="114x114" href="favicons/apple-icon-114x114.png">
   <link rel="apple-touch-icon" sizes="120x120" href="favicons/apple-icon-120x120.png">
   <link rel="apple-touch-icon" sizes="144x144" href="favicons/apple-icon-144x144.png">
   <link rel="apple-touch-icon" sizes="152x152" href="favicons/apple-icon-152x152.png">
   <link rel="apple-touch-icon" sizes="180x180" href="favicons/apple-icon-180x180.png">
   <link rel="icon" type="image/png" sizes="192x192"  href="favicons/android-icon-192x192.png">
   <link rel="icon" type="image/png" sizes="32x32" href="favicons/favicon-32x32.png">
   <link rel="icon" type="image/png" sizes="96x96" href="favicons/favicon-96x96.png">
   <link rel="icon" type="image/png" sizes="16x16" href="favicons/favicon-16x16.png">
   <meta name="msapplication-TileColor" content="#ffffff">
   <meta name="msapplication-TileImage" content="favicons/ms-icon-144x144.png">
   <meta name="theme-color" content="#ffffff">

   <!-- Bootstrap CSS files-->
   <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/3.4.1/css/bootstrap.min.css" integrity="sha384-HSMxcRTRxnN+Bdg0JdbxYKrThecOKuH5zCYotlSAcp1+c8xmyTe9GYg1l9a69psu" crossorigin="anonymous">

   <!-- jQuery UI CSS (optional) -->
   <link rel="stylesheet" href="https://ajax.googleapis.com/ajax/libs/jqueryui/1.12.1/themes/smoothness/jquery-ui.css">

   <!-- Google web fonts -->
   <link href="https://fonts.googleapis.com/css?family=Open+Sans:300,400,400i,600,700" rel="stylesheet">
   <link href="https://fonts.googleapis.com/css?family=Montserrat:400,400i,500,500i,600" rel="stylesheet">

   <!-- Font Awesome Web Icons -->
   <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.8.1/css/all.css" integrity="sha384-50oBUHEmvpQ+1lW4y57PTFmhCaXp0ML5d60M1M7uH2+nqUivzIebhndOJK28anvf" crossorigin="anonymous">

   <!-- Academicons Courtesy of https://jpswalsh.github.io/academicons/ -->
   <link rel="stylesheet" href="https://cdn.rawgit.com/jpswalsh/academicons/master/css/academicons.min.css">

   <!-- Local styles -->
   <link rel="stylesheet" href="css/main.css">

</head>

<body>

   <!-- navbar include -->
   <div w3-include-html="navbar.html"></div>

   <div class="spacer-div-3 hidden-xs hidden-xs"></div>

   <!-- Main content    -->
   <div id="main-container" class="container">

      <div class="row">
         <div class="col-sm-12">
            <h1>Research</h1>
            <!-- <p>I favor a {DESCRIBE MAIN THEORETICAL/METHODOLOGICAL APPROACH IN 1 SENTENCE}.</p> -->

            <p>
            	The usual paradigm of <em>computational photography</em> is to jointly design hardware and software for specific applications to enhance overall performance and efficiency.
				However, more often than not, devising new hardware for each application is cumbersome and expensive. These hardware setups are often bulky and require meticulous calibration, making them ill-suited for practical, real-world scenarios.
				My research tackles the well-established computational photography problems and achieves better performance by re-purposing existing hardware with minimal changes.
				While this seems ambitious, my research uses state-of-the-art deep learning techniques to achieve this goal.
            </p>

            <p>
            	While deep-learning algorithms achieve significantly higher performance on several tasks, they still require informative inputs.
				Images and videos captured using traditional cameras have their limitations and are not always suitable for several applications.
				For instance, a learning-based algorithm proposed for video reconstruction from a single blurred image suffers from motion ambiguity leading to poor reconstructions.
				An additional input that encodes the motion information would significantly improve the algorithm performance.
				Hence, in my research, I go beyond the traditional cameras and explore novel sensors and setups most suitable for my application.
				Along with the suitability, aspects like the hardware's power consumption, commercial availability, form factor are also considered.
				After choosing the proper hardware, the task is to design a novel learning-based algorithm for each application.
				My research considers two well-studied computational photography problems: high-frame-rate video and light-field video reconstruction.
            </p>

            <!-- <p>I focus specifically in these areas:</p> -->

            <!-- List of Research interests -->
            <!-- <ul class="push-down-1">
               <li><em>Computational photography </em>&mdash; Although several advancements have been made in the camera industry, the basic design, lens system + sensor (<a href="https://en.wikipedia.org/wiki/Camera_obscura">camera obscura</a>), still remains the same. 
               	The field of computational photography aims at redesigning the camera optics to capture an encoded measurement of the real scene. 
               	A signal processing algorithm is further developed to decode information which would be previously not possible to capture with a conventional imaging setup.
               Superior perfomance in several conventional imaging processing tasks such as deblurring, depth estimation, extended depth of field imaging, light field imaging, etc. </li>
               <li><em>Deep learning </em>&mdash; Deep learning is a broader form of machine learning techniques and considered as a form of artifical intelligence. This field involves the use of artifical neural networks that work by learning compact representations for data. The powerful representation learning of these techniques are used in computational photography most commonly for solving linear inverse problems such as deblurring, compressive sensing signal recovery, etc. </li>
               <li><em>{AREA 3}</em>&mdash;{BRIEF DESCRIPTION OF AREA}</li>
               <li><em>{AREA 4}</em>&mdash;{BRIEF DESCRIPTION OF AREA}</li>
               <li><em>{AREA 5}</em>&mdash;{BRIEF DESCRIPTION OF AREA}</li>
               <li><em>{AREA 6}</em>&mdash;{BRIEF DESCRIPTION OF AREA}</li>
            </ul> -->

            <!-- Publication -->
            <h3 class="push-down-4"><span>Select Publications</span></h3>

            <h5>Papers under review</h5>
            <ul class="publications">
            	<li> 
            		<b>Prasan Shedligeri</b>, Florian Schiffers, Semih Barutcu, Pablo Ruiz, Aggelos Katsaggelos & Oliver Cossairt. (submitted Jan 2021) Improving Acquisition Speed  of X-Ray Ptychography through Spatial Undersampling. Under Review at <em>IEEE ICIP 2021</em>
            	</li>
            	
            </ul>


            <h5>Published Papers</h5>

        	<ul class="publications">
        		<li> 
            		<b>Prasan Shedligeri</b>, Florian Schiffers, Semih Barutcu, Pablo Ruiz, Aggelos Katsaggelos & Oliver Cossairt. (2021) Regularization for Undersampled Ptychography. Accepted at <em>OSA COSI 2021</em> doi to be assigned 
            	</li>
               <li>
                  <b>Prasan Shedligeri</b> & Kaushik Mitra. (2021) High Frame Rate Optical Flow Estimation from Event Sensors via Intensity Estimation. Accepted at <em>Elsevier Journal of Computer Vision and Image Understanding,</em> doi to be assigned 
                  <a href="./pages/webpage-CVIU/resources/paper.pdf" target="_blank" rel="noopener noreferrer">[Paper]</a>
                  <a href="./pages/webpage-CVIU/index.html" target="_blank" rel="noopener noreferrer">[Webpage]</a>
                </li>
            	<li>
                  <b>Prasan Shedligeri</b>, Anupama S & Kaushik Mitra. (2021) CodedRecon: Video reconstruction for coded exposure imaging techniques. Accepted at <em>Elsevier Journal of Software Impacts,</em> https://doi.org/10.1016/j.simpa.2021.100064 
               	<a href="https://www.sciencedirect.com/science/article/pii/S2665963821000129" target="_blank" rel="noopener noreferrer">[Paper]</a>
               	<a href="https://github.com/asprasan/unified_framework" target="_blank" rel="noopener noreferrer">[Code]</a>
                  <a href="https://asprasan.github.io/unified_framework/" target="_blank" rel="noopener noreferrer">[Webpage]</a>
               </li>

            	<li>
                  <b>Prasan Shedligeri</b>, Anupama S & Kaushik Mitra. (2021) A Unified Framework for Compressive Video Recovery from Coded Exposure Techniques. Accepted at <em>IEEE/CVF Winter Conference on Applications of Computer Vision,</em> doi to be assigned 
               	<a href="https://arxiv.org/abs/2011.05532" target="_blank" rel="noopener noreferrer">[Preprint]</a>
               	<a href="https://docs.google.com/presentation/d/1TqyRWTtNqIssMJ_nnHTTNLNbdP_oMqGtBlgvnaNTcYI/edit?usp=sharing" target="_blank" rel="noopener noreferrer">[Slides]</a>
               	<a href="https://drive.google.com/file/d/1GGpgzTGXnE1XzONJOv81iK23TVIfkAvB/view?usp=sharing" target="_blank" rel="noopener noreferrer">[Supplementary]</a>
               	<a href="https://github.com/asprasan/unified_framework" target="_blank" rel="noopener noreferrer">[Code]</a>
               	<a href="https://asprasan.github.io/unified_framework/" target="_blank" rel="noopener noreferrer">[Webpage]</a>
               </li>

               <li>
                  Anupama S, <b>Prasan Shedligeri</b>, Abhishek Pal & Kaushik Mitra. (2020) Video Reconstruction by Spatio-Temporal Fusion of Blurred-Coded Image Pair. Accepted at <em>IEEE International Conference on Pattern Recognition,</em> doi to be assigned 
                  <a href="https://arxiv.org/abs/2010.10052" target="_blank" rel="noopener noreferrer">[Preprint]</a>
                  <a href="https://docs.google.com/presentation/d/1VxjBlD70bW-hMiSQlJLm6akre9zi0_Ob6bt6pZO5EdE/edit?usp=sharing" target="_blank" rel="noopener noreferrer">[Slides]</a>
                  <a href="https://drive.google.com/file/d/1u99_tjrFW56qvVXm46CmA-zBOvI1-56o/view?usp=sharing" target="_blank" rel="noopener noreferrer">[Supplementary]</a>
                  <a href="https://github.com/asprasan/codedblurred" target="_blank" rel="noopener noreferrer">[Code]</a>
                  <a href="https://asprasan.github.io/codedblurred/" target="_blank" rel="noopener noreferrer">[Webpage]</a>
           		</li>

               <li> 
                  <b>Prasan Shedligeri</b> & Kaushik Mitra. (2019) Photorealistic image reconstruction from hybrid intensity and event-based sensor. <em> Journal of Electronic Imaging, 28</em>(6), International Society for Optics and Photonics. doi:10.1117/1.JEI.28.6.063012. <a href="https://doi.org/10.1117/1.JEI.28.6.063012" target="_blank" rel="noopener noreferrer">[Paper]</a> <a href="https://arxiv.org/abs/1805.06140" target="_blank" rel="noopener noreferrer">[Arxiv preprint]</a> 
               </li>

               <li> 
                  <b>Prasan Shedligeri</b> & Kaushik Mitra. (2019) Live Demonstration: Joint Estimation of Optical Flow and Intensity Image From Event Sensors. <em>IEEE CVPR workshop on Event Sensors</em>. <a href="https://openaccess.thecvf.com/content_CVPRW_2019/papers/EventVision/Shedligeri_Live_Demonstration_Joint_Estimation_of_Optical_Flow_and_Intensity_Image_CVPRW_2019_paper.pdf" target="_blank" rel="noopener noreferrer">[Paper]</a> 
               </li>


               <li> 
                  <b>Prasan Shedligeri</b>, <a href="https://sreyas-mohan.github.io/" target="_blank" rel="noopener noreferrer">Sreyas Mohan</a> & Kaushik Mitra. (2017) Data driven coded aperture design for depth recovery. <em>IEEE International Conference on Image Processing,</em> 56-60. doi:10.1109/ICIP.2017.8296242 <a href="https://doi.org/10.1109/ICIP.2017.8296242" target="_blank" rel="noopener noreferrer">[Paper]</a> <a href="">[Preprint]</a> <a href="http://www.ee.iitm.ac.in/comp_photolab/project-data-driven-coded-aperture-design.html" target="_blank" rel="noopener noreferrer">[Website]</a> 
               </li>
            </ul>

            <!-- <h5>Submitted for Publication</h5> -->

<!--             <ul class="publications">
               <li>LastName, P., & Lastname, Q. (1999). <em>Book title goes here</em> (2nd ed.) City, CA: Publishing House.</li>
               <li>Lastname, X. (1999). Article title. <em>Journal Title, 33</em>(5), 100-110. doi:10.1099/1525.1999.12</li>
               <li>Lastname, X. (1999). Article title. <em>Journal Title, 33</em>(5), 100-110. doi:10.1099/1525.1999.12</li>
               <li>Lastname, X. (1999). Article title. <em>Journal Title, 33</em>(5), 100-110. doi:10.1099/1525.1999.12</li>
            </ul> -->

            <!-- <h5>Working Papers</h5> -->

<!--             <ul class="publications">
               <li>LastName, P., & Lastname, Q. (1999). <em>Book title goes here</em> (2nd ed.) City, CA: Publishing House.</li>
               <li>Lastname, X. (1999). Article title. <em>Journal Title, 33</em>(5), 100-110. doi:10.1099/1525.1999.12</li>
               <li>Lastname, X. (1999). Article title. <em>Journal Title, 33</em>(5), 100-110. doi:10.1099/1525.1999.12</li>
               <li>Lastname, X. (1999). Article title. <em>Journal Title, 33</em>(5), 100-110. doi:10.1099/1525.1999.12</li>
            </ul> -->

            <!-- Dissertation abstract -->
            <!-- <h3 class="push-down-3"><span>Dissertation</span></h3> -->
            <!-- <p>{BRIEF PARAGRAPH(S) ABSTRACT OF YOUR DISSERTATION}</p> -->

            <!-- Sample quote from the dissertation -->
            <!-- <blockquote>{SAMPLE/QUOTE FROM YOUR DISSERTATION} -->
               <!-- <footer> -->
                  <!-- Smith, Jane. (2015). <em>Title of Dissertation.</em> (Doctoral dissertation). Retrieved from Some Online Repository. (http://online-repository.com) -->
               <!-- </footer> -->
            <!-- </blockquote> -->


            <!-- Read More Button -- link to the dissertation -->
            <!-- <p class="text-left"> -->
               <!-- <a id="link-to-docs" role="button" class="btn btn-default" href="#" target="_blank"> -->
                  <!-- <i class="far fa-file-pdf fa-fw" aria-hidden="true"></i>&nbsp; Read More -->
               <!-- </a> -->
            <!-- </p> -->

         </div>
      </div>

   </div>

   <!-- Back-to-top button -->
   <a role="button" id="topper" data-toggle="tooltip" data-placement="top" title="Top" class="btn scroll-link" href="#top"><i class="fa fa-fw fa-2x fa-caret-up" aria-hidden="true"></i></a>

   <!-- footer include -->
   <div w3-include-html="footer.html"></div>

   <!-- jQuery -->
   <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>

   <!-- Bootstrap JS Library -->
   <script src="https://stackpath.bootstrapcdn.com/bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha384-aJ21OjlMXNL5UyIl/XNwTMqvzeRMZH2w8c5cRVpzpU8Y5bApTppSuUkhZXN0VxHd" crossorigin="anonymous"></script>

   <!-- html file include script | used for navbar and footer -->
   <script src="js/w3data.js"></script>
   <script>
      w3IncludeHTML()
   </script>

   <!-- Local scripts -->
   <script src="js/main.js"></script>

   <script>
      $(document).ready(function() {
         $("li#research a").addClass("active");
         $("li#research a").addClass("hvr-bubble-bottom");

      });
   </script>

</body>

</html>
